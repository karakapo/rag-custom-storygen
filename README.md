# ğŸ“– Storymaker

Storymaker, yapay zeka desteÄŸiyle Ã§ocuklara yÃ¶nelik hikayeler oluÅŸturan bir uygulamadÄ±r. Ä°ki farklÄ± ÅŸekilde hikaye Ã¼retimi mÃ¼mkÃ¼ndÃ¼r:

1. **Serbest Mod:** KullanÄ±cÄ±nÄ±n girdiÄŸi prompt, optimizasyondan sonra bir LLM'e (Large Language Model) gÃ¶nderilir ve modelden gelen yanÄ±t hikaye olarak sunulur.
2. **RAG TabanlÄ± Mod:** Daha yenilikÃ§i ve kontrollÃ¼ olan bu yÃ¶ntemde, Ã¶nceden hazÄ±rlanmÄ±ÅŸ veri kullanÄ±larak Retrieval-Augmented Generation (RAG) yÃ¶ntemiyle hikaye Ã¼retilir.

RAG modunda, hikayenin bileÅŸenlerini oluÅŸturan 8 farklÄ± kategoriye ayrÄ±lmÄ±ÅŸ Ã¶rnekler vektÃ¶r veritabanÄ±na (vector database) kaydedilir:
- `Main_character`
- `Environment`
- `Main_conflict`
- `Moral`
- `Plot`
- `Character_goal`
- `Genre`
- `Final_type`

KullanÄ±cÄ±nÄ±n verdiÄŸi prompt, bu vektÃ¶r veritabanÄ±nda her kategori iÃ§in semantik olarak en yakÄ±n 3 Ã¶rneÄŸi bulmak iÃ§in sorgulanÄ±r. ArdÄ±ndan her kategoriden rastgele bir Ã¶rnek seÃ§ilir ve bu 8 bileÅŸen, LLM'e input olarak gÃ¶nderilir. Model bu yapÄ±dan yola Ã§Ä±karak bÃ¼tÃ¼nsel bir hikaye Ã¼retir.

Bu yÃ¶ntemin avantajÄ±:
- LLM'e yeniden eÄŸitim gerekmeden yaratÄ±cÄ± ve kontrollÃ¼ iÃ§erik Ã¼retilmesi,
- Ã‡ocuklara uygunluÄŸu artÄ±rmak iÃ§in Ã§Ä±ktÄ±nÄ±n daha kontrollÃ¼ bir ÅŸekilde sÄ±nÄ±rlandÄ±rÄ±lmasÄ±,
- KullanÄ±cÄ±nÄ±n verdiÄŸi girdinin belirli bir Ã¶lÃ§Ã¼de esnetilerek Ã¶rnek tabana uygun hale getirilmesi.

---

## ğŸ¤– Neden RAG KullandÄ±m?

RAG, bÃ¼yÃ¼k dil modellerine daha anlamlÄ± ve yÃ¶nlendirilmiÅŸ veri saÄŸlayarak:
- YaratÄ±cÄ±lÄ±ÄŸÄ± artÄ±rÄ±r,
- TutarlÄ±lÄ±ÄŸÄ± korur,
- KullanÄ±cÄ± girdilerini toleranslÄ± ÅŸekilde yorumlayabilir.

AyrÄ±ca model eÄŸitimi gerektirmeden anlamlÄ± Ã§Ä±ktÄ±lar Ã¼retmeye olanak saÄŸlar. Bu, Ã¶zellikle Ã§ocuklar iÃ§in iÃ§erik Ã¼retirken gÃ¼venlik ve kalite aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k avantaj saÄŸlar.

---

## ğŸ› ï¸ Tech Stack

- **Backend:** FastAPI
- **Frontend:** Basit HTML/CSS + JavaScript (Yapay zeka destekli ide ile yapÄ±ldÄ±)
- **Vector DB:** Qdrant
- **LLM API:** Google Gemini 
- **Veri Ä°ÅŸleme:** Python + LangChain

---

## ğŸš€ Sistem GeliÅŸim SÃ¼reci

- ğŸ¯ DoÄŸrudan LLM'e istek: Prompt direkt verildi â†’ Ã§Ä±ktÄ± yÃ¼zeysel ve tutarsÄ±zdÄ±.
- âœï¸ Prompt optimizasyonu: YapÄ±landÄ±rÄ±lmÄ±ÅŸ promptlarla kÄ±smi iyileÅŸme saÄŸlandÄ±.
- ğŸ” Ä°lk RAG denemesi: Prompt parÃ§alanarak kategori bazlÄ± paralel arama yapÄ±ldÄ± â†’ promtp parÃ§alama zayÄ±f kaldÄ±.
- ğŸ§© GeliÅŸmiÅŸ RAG sistemi: Prompt bÃ¼tÃ¼n alÄ±ndÄ±, her kategoriye ayrÄ± arama yapÄ±ldÄ± â†’ Ã§Ä±ktÄ± tutarlÄ± ve anlamlÄ± hale geldi.
- ğŸ”€ Alternatif strateji: Prompt optimizasyonu yÃ¶ntemi opsiyonel bÄ±rakÄ±ldÄ±, kullanÄ±cÄ± iki sistem arasÄ±nda seÃ§im yapabiliyor.

### ğŸ“ˆ SÃ¼reÃ§ AkÄ±ÅŸÄ±

[DoÄŸrudan LLM'e Ä°stek] --> [Prompt Optimizasyonu] --> [Ä°lk RAG Denemesi] --> [GeliÅŸtirilmiÅŸ RAG Sistemi] --> [Alternatif Strateji Eklenmesi]


---

## ğŸš§ Eklenecek Ã–zellikler

- [ ] KullanÄ±cÄ± giriÅŸi ve oturum yÃ¶netimi
- [ ] VektÃ¶r veritabanÄ±nÄ±n daha zengin ve dengeli hale getirilmesi
- [ ] KullanÄ±cÄ±nÄ±n kendi karakterini oluÅŸturabilme
- [ ] Hikayeleri PDF olarak dÄ±ÅŸa aktarabilme
- [ ] KullanÄ±cÄ±ya Ã¶zel yan karakter ekleme
- [ ] Daha test edilebilir bir yapÄ± kurmak

---

## âš¡ï¸ NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?

### 1. Backend (FastAPI) Kurulumu ve Ã‡alÄ±ÅŸtÄ±rÄ±lmasÄ±

```bash
cd backend
python -m venv venv
# Windows:
venv\Scripts\activate
# Mac/Linux:
# source venv/bin/activate

pip install -r requirements.txt

# Sunucuyu baÅŸlatÄ±n
uvicorn main:app --reload
```

VarsayÄ±lan olarak FastAPI backend'i `http://127.0.0.1:8000` adresinde Ã§alÄ±ÅŸacaktÄ±r.

---

### 2. Frontend (Statik HTML/JS) Kurulumu ve Ã‡alÄ±ÅŸtÄ±rÄ±lmasÄ±

```bash
cd frontend
npm install
npm start
```

Bu komutlar, frontend'i `http://localhost:3000` adresinde baÅŸlatÄ±r.

---

### 3. Notlar

- Backend ve frontend'i aynÄ± anda Ã§alÄ±ÅŸtÄ±rmalÄ±sÄ±nÄ±z.
- Gerekirse `.env` dosyasÄ± ile backend ayarlarÄ±nÄ± yapabilirsiniz.
- Backend, hikaye Ã¼retimi iÃ§in LLM API'lerini (Ã¶r. Google Gemini) kullanÄ±r; API anahtarÄ±nÄ±zÄ± `.env` dosyasÄ±na eklemelisiniz.
